# embedding_search.py
# ----------------------------------------------------------
# En s√∂kmotor som anv√§nder AI-embeddings f√∂r att hitta
# relevanta dokument baserat p√• anv√§ndarens fr√•ga.
# ----------------------------------------------------------

import os
import json
import math
from database_manager import get_connection
from embedding_generator import generate_embedding
from colorama import Fore, Style, init

from search_logger import log_search

# Aktiverar f√§rg i terminalen
init(autoreset=True)


# ----------------------------------------------------------
# Hj√§lpfunktioner f√∂r vektorber√§kning
# ----------------------------------------------------------

def dot(a, b):
    """Ber√§knar skal√§rprodukt (dot product) mellan tv√• vektorer"""
    return sum(x * y for x, y in zip(a, b))


def norm(a):
    """Ber√§knar vektorns l√§ngd (magnitud)"""
    return math.sqrt(dot(a, a))


def cosine_similarity(a, b):
    """Ber√§knar cosinuslikhet mellan tv√• vektorer"""
    return dot(a, b) / (norm(a) * norm(b) + 1e-9)


# ----------------------------------------------------------
# Huvudfunktion f√∂r s√∂kning
# ----------------------------------------------------------

def embedding_search():
    print("üîç Startar s√∂kning med embeddings...")
    query = input("Ange din s√∂kfr√•ga: ")

    # Skapar embedding-vektor f√∂r fr√•gan
    query_vector = generate_embedding(query)

    # H√§mtar embeddings fr√•n databasen
    conn = get_connection()
    cursor = conn.cursor()
    cursor.execute("""
        SELECT DISTINCT f.path, e.vector, e.summary
        FROM embeddings e
        JOIN files f ON e.file_id = f.id
    """)
    rows = cursor.fetchall()
    conn.close()

    results = []

    for name, vector_json, summary in rows:
        p = name.lower()

        # Filtrera bort on√∂diga eller k√§nsliga filer
        if any(s in p for s in ["node_modules", ".asar.unpacked", "license", "github-recovery", ".git"]):
            continue

        # Hoppa √∂ver filer med f√∂r kort text
        if not summary or len(summary) < 60:
            continue

        # Ladda embedding-vektorn fr√•n databasen
        vector = json.loads(vector_json)

        # Ber√§kna likhet
        similarity = cosine_similarity(query_vector, vector)

        results.append((name, summary, similarity))

    # Sortera resultaten (h√∂gst likhet f√∂rst)
    results.sort(key=lambda x: x[2], reverse=True)

    # ----------------------------------------------------------
    # Skriv ut resultat
    # ----------------------------------------------------------
    print("\nüìÑ S√∂kningsresultat (topp 5):\n" + "-" * 60)

    from search_logger import log_search  # Import en g√•ng

    for i, (name, summary, similarity) in enumerate(results[:5], 1):
        percent = round(similarity * 100, 1)

        # üé® F√§rg baserat p√• likhet
        if percent >= 70:
            color = Fore.GREEN
        elif percent >= 40:
            color = Fore.YELLOW
        else:
            color = Fore.RED

        # üßæ Skriv ut varje rad
        file_title = os.path.basename(name)
        print(f"{color}{i}. {file_title}")
        print(f"   üîπ Match: {percent}%")
        print(f"   üìò Sammanfattning: {summary[:200]}...")
        print("-" * 60)

# üß† N√§r allt √§r utskrivet ‚Üí logga s√∂kningen EN g√•ng
    log_search(query, results)


# ----------------------------------------------------------
# Starta programmet
# ----------------------------------------------------------
if __name__ == "__main__":
    embedding_search()
